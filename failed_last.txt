============================= test session starts =============================
platform win32 -- Python 3.13.12, pytest-8.4.2, pluggy-1.6.0 -- C:\Users\Robin\AppData\Local\Microsoft\WindowsApps\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\python.exe
cachedir: .pytest_cache
hypothesis profile 'default'
rootdir: C:\Users\Robin\MnemoCore-Infrastructure-for-Persistent-Cognitive-Memory
configfile: pytest.ini
plugins: anyio-4.11.0, hypothesis-6.151.9, langsmith-0.4.32, locust-2.43.0, asyncio-1.2.0, cov-7.0.0
asyncio: mode=Mode.AUTO, debug=False, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 74 items / 70 deselected / 4 selected
run-last-failure: rerun previous 4 failures (skipped 65 files)

tests/test_anticipatory.py::test_anticipatory_memory FAILED              [ 25%]
tests/test_attention_extended.py::TestXORAttentionPropertyBased::test_alpha_beta_valid_combinations FAILED [ 50%]
tests/test_reliability.py::TestCircuitBreakerDecorators::test_sync_decorator_in_async_context PASSED [ 75%]
tests/test_tier_conflict.py::test_get_memory_demotion_race_condition PASSED [100%]

================================== FAILURES ===================================
__________________________ test_anticipatory_memory ___________________________
tests\test_anticipatory.py:80: in test_anticipatory_memory
    assert node_b in test_engine.tier_manager.hot, "Anticipatory engine failed to preload node_b."
E   AssertionError: Anticipatory engine failed to preload node_b.
E   assert '80c4a153-b2e5-4c63-a5d4-62abc0198709' in {'bb7ea7d6-b040-4522-9faa-d1eb50a0aef7': MemoryNode(id='bb7ea7d6-b040-4522-9faa-d1eb50a0aef7', hdv=BinaryHDV(dim=1024, popcount=492/1024), content='I love learning about Machine Learning and AI algorithms.', metadata={'eig': 0.48046875}, created_at=datetime.datetime(2026, 2, 24, 21, 15, 54, 383481, tzinfo=datetime.timezone.utc), last_accessed=datetime.datetime(2026, 2, 24, 21, 15, 54, 543616, tzinfo=datetime.timezone.utc), tier='hot', access_count=15, ltp_strength=2.7725886708506198, epistemic_value=0.5522864383915137, pragmatic_value=0.0, previous_id=None, stability=2.386294361119891, review_candidate=False, embedding_model_id='binary_hdv', embedding_version=1, embedding_checksum='')}
E    +  where {'bb7ea7d6-b040-4522-9faa-d1eb50a0aef7': MemoryNode(id='bb7ea7d6-b040-4522-9faa-d1eb50a0aef7', hdv=BinaryHDV(dim=1024, popcount=492/1024), content='I love learning about Machine Learning and AI algorithms.', metadata={'eig': 0.48046875}, created_at=datetime.datetime(2026, 2, 24, 21, 15, 54, 383481, tzinfo=datetime.timezone.utc), last_accessed=datetime.datetime(2026, 2, 24, 21, 15, 54, 543616, tzinfo=datetime.timezone.utc), tier='hot', access_count=15, ltp_strength=2.7725886708506198, epistemic_value=0.5522864383915137, pragmatic_value=0.0, previous_id=None, stability=2.386294361119891, review_candidate=False, embedding_model_id='binary_hdv', embedding_version=1, embedding_checksum='')} = <mnemocore.core.tier_manager.TierManager object at 0x0000017B0B24E7B0>.hot
E    +    where <mnemocore.core.tier_manager.TierManager object at 0x0000017B0B24E7B0> = <mnemocore.core.engine.HAIMEngine object at 0x0000017B0B1FBCB0>.tier_manager
---------------------------- Captured stderr setup ----------------------------
2026-02-24 22:15:53.220 | INFO     | mnemocore.core.tier_manager:_init_hnsw_index:135 - HNSWIndexManager initialized for HOT tier (dim=1024, M=16)
2026-02-24 22:15:53.223 | INFO     | mnemocore.core.binary_hdv:__init__:541 - Persistent vector cache enabled at ./data/vector_cache.sqlite
2026-02-24 22:15:53.233 | INFO     | mnemocore.core.binary_hdv:__init__:541 - Persistent vector cache enabled at ./data/vector_cache.sqlite
---------------------------- Captured stderr call -----------------------------
2026-02-24 22:15:54.228 | INFO     | mnemocore.core.synapse_index:load_from_file:335 - SynapseIndex loaded 426 edges from ./data/synapses.json\n2026-02-24 22:15:54.228 | INFO     | mnemocore.core.semantic_consolidation:start:157 - SemanticConsolidationWorker started \u2014 runs at 03:00 UTC\n2026-02-24 22:15:54.229 | INFO     | mnemocore.core.immunology:start:121 - ImmunologyLoop started \u2014 sweep every 300.0s\n2026-02-24 22:15:54.231 | INFO     | mnemocore.core.subconscious_ai:__init__:364 - SubconsciousAIWorker created (provider=ollama, model=phi3.5:latest, enabled=True)\n2026-02-24 22:15:54.232 | DEBUG    | mnemocore.utils.process:lower_process_priority:18 - Lowered Windows process priority to BELOW_NORMAL\n2026-02-24 22:15:54.243 | INFO     | mnemocore.core.subconscious_ai:start:423 - [Phase 4.4 BETA] SubconsciousAI started (interval=120s, dry_run=False)\n2026-02-24 22:15:54.243 | INFO     | mnemocore.core.engine_lifecycle:initialize:114 - Phase 4.4 SubconsciousAI worker started (BETA).\n2026-02-24 22:15:54.243 | INFO     | mnemocore.core.engine_lifecycle:initialize:118 - Phase 4.0 background workers started (consolidation + immunology).\n2026-02-24 22:15:54.243 | DEBUG    | mnemocore.core.semantic_consolidation:_schedule_loop:179 - Next semantic consolidation in 5.7h\n2026-02-24 22:15:54.346 | DEBUG    | mnemocore.core.subconscious_ai:_run_cycle:513 - [SubconsciousAI] Cycle 1 (dreaming) completed in 2ms\n2026-02-24 22:15:54.399 | DEBUG    | mnemocore.core.attention:build_attention_mask:106 - Built XOR attention mask \u2014 query/context Hamming dist = 0.0000\n2026-02-24 22:15:54.399 | DEBUG    | mnemocore.core.engine_core:_strengthen_recall_associations:811 - Strengthened associations for 1 co-retrieved memories\n2026-02-24 22:15:54.402 | DEBUG    | mnemocore.core.attention:build_attention_mask:106 - Built XOR attention mask \u2014 query/context Hamming dist = 0.0000\n2026-02-24 22:15:54.402 | DEBUG    | mnemocore.core.engine_core:event_bus:197 - [EngineCore] EventBus initialized\n2026-02-24 22:15:54.402 | DEBUG    | mnemocore.core.engine_core:store:529 - Added memory bb7ea7d6-b040-4522-9faa-d1eb50a0aef7 to association network\n2026-02-24 22:15:54.402 | INFO     | mnemocore.core.engine_core:store:536 - Stored memory bb7ea7d6-b040-4522-9faa-d1eb50a0aef7 (EIG: 0.4805)\n2026-02-24 22:15:54.402 | DEBUG    | mnemocore.core.engine_core:_strengthen_recall_associations:811 - Strengthened associations for 1 co-retrieved memories\n2026-02-24 22:15:54.519 | DEBUG    | mnemocore.core.attention:build_attention_mask:106 - Built XOR attention mask \u2014 query/context Hamming dist = 0.2510\n2026-02-24 22:15:54.519 | DEBUG    | mnemocore.core.engine_core:_strengthen_recall_associations:811 - Strengthened associations for 2 co-retrieved memories\n2026-02-24 22:15:54.529 | DEBUG    | mnemocore.core.attention:build_attention_mask:106 - Built XOR attention mask \u2014 query/context Hamming dist = 0.2510\n2026-02-24 22:15:54.529 | DEBUG    | mnemocore.core.synapse_index:add_or_fire:100 - Synapse created: 80c4a153 \u2194 bb7ea7d6\n2026-02-24 22:15:54.529 | DEBUG    | mnemocore.core.bayesian_ltp:observe_synapse:171 - Synapse (80c4a153\u2194bb7ea7d6) Bayesian update \u2014 success=True \u03b1=2.00 \u03b2=2.00 \u2192 p_mean=0.5000 \xb1 0.2236\n2026-02-24 22:15:54.529 | DEBUG    | mnemocore.core.anticipatory:predict_and_preload:48 - Anticipatory engine pre-loading 1 predicted nodes.\n2026-02-24 22:15:54.529 | DEBUG    | mnemocore.core.engine_core:_strengthen_recall_associations:811 - Strengthened associations for 2 co-retrieved memories\n2026-02-24 22:15:54.534 | DEBUG    | mnemocore.core.engine_core:store:529 - Added memory 80c4a153-b2e5-4c63-a5d4-62abc0198709 to association network\n2026-02-24 22:15:54.535 | INFO     | mnemocore.core.engine_core:store:536 - Stored memory 80c4a153-b2e5-4c63-a5d4-62abc0198709 (EIG: 0.5039)\n2026-02-24 22:15:54.535 | DEBUG    | mnemocore.core.bayesian_ltp:observe_synapse:171 - Synapse (80c4a153\u2194bb7ea7d6) Bayesian update \u2014 success=True \u03b1=3.00 \u03b2=2.00 \u2192 p_mean=0.6000 \xb1 0.2000\n2026-02-24 22:15:54.543 | DEBUG    | mnemocore.core.attention:build_attention_mask:106 - Built XOR attention mask \u2014 query/context Hamming dist = 0.0000\n2026-02-24 22:15:54.543 | DEBUG    | mnemocore.core.gap_detector:assess_query:182 - Gap detected [sparse]: 'I love learning about Machine Learning and AI algorithms.' (conf=1.224 priority=0.485)\n2026-02-24 22:15:54.543 | DEBUG    | mnemocore.core.anticipatory:predict_and_preload:48 - Anticipatory engine pre-loading 1 predicted nodes.\n2026-02-24 22:15:54.543 | DEBUG    | mnemocore.core.engine_core:_strengthen_recall_associations:811 - Strengthened associations for 1 co-retrieved memories
______ TestXORAttentionPropertyBased.test_alpha_beta_valid_combinations _______
tests\test_attention_extended.py:398: in test_alpha_beta_valid_combinations
    @given(st.floats(min_value=0.0, max_value=1.0),
               ^^^^^^^
E   hypothesis.errors.FailedHealthCheck: It looks like this test is filtering out a lot of inputs. 0 inputs were generated successfully, while 50 inputs were filtered out. 
E   
E   An input might be filtered out by calls to assume(), strategy.filter(...), or occasionally by Hypothesis internals.
E   
E   Applying this much filtering makes input generation slow, since Hypothesis must discard inputs which are filtered out and try generating it again. It is also possible that applying this much filtering will distort the domain and/or distribution of the test, leaving your testing less rigorous than expected.
E   
E   If you expect this many inputs to be filtered out during generation, you can disable this health check with @settings(suppress_health_check=[HealthCheck.filter_too_much]). See https://hypothesis.readthedocs.io/en/latest/reference/api.html#hypothesis.HealthCheck for details.
--------------------------------- Hypothesis ----------------------------------
You can add @seed(62089256824609268545409143279920280362) to this test or run pytest with --hypothesis-seed=62089256824609268545409143279920280362 to reproduce this failure.
=========================== short test summary info ===========================
FAILED tests/test_anticipatory.py::test_anticipatory_memory - AssertionError: Anticipatory engine failed to preload node_b.
assert '80c4a153-b2e5-4c63-a5d4-62abc0198709' in {'bb7ea7d6-b040-4522-9faa-d1eb50a0aef7': MemoryNode(id='bb7ea7d6-b040-4522-9faa-d1eb50a0aef7', hdv=BinaryHDV(dim=1024, popcount=492/1024), content='I love learning about Machine Learning and AI algorithms.', metadata={'eig': 0.48046875}, created_at=datetime.datetime(2026, 2, 24, 21, 15, 54, 383481, tzinfo=datetime.timezone.utc), last_accessed=datetime.datetime(2026, 2, 24, 21, 15, 54, 543616, tzinfo=datetime.timezone.utc), tier='hot', access_count=15, ltp_strength=2.7725886708506198, epistemic_value=0.5522864383915137, pragmatic_value=0.0, previous_id=None, stability=2.386294361119891, review_candidate=False, embedding_model_id='binary_hdv', embedding_version=1, embedding_checksum='')}
 +  where {'bb7ea7d6-b040-4522-9faa-d1eb50a0aef7': MemoryNode(id='bb7ea7d6-b040-4522-9faa-d1eb50a0aef7', hdv=BinaryHDV(dim=1024, popcount=492/1024), content='I love learning about Machine Learning and AI algorithms.', metadata={'eig': 0.48046875}, created_at=datetime.datetime(2026, 2, 24, 21, 15, 54, 383481, tzinfo=datetime.timezone.utc), last_accessed=datetime.datetime(2026, 2, 24, 21, 15, 54, 543616, tzinfo=datetime.timezone.utc), tier='hot', access_count=15, ltp_strength=2.7725886708506198, epistemic_value=0.5522864383915137, pragmatic_value=0.0, previous_id=None, stability=2.386294361119891, review_candidate=False, embedding_model_id='binary_hdv', embedding_version=1, embedding_checksum='')} = <mnemocore.core.tier_manager.TierManager object at 0x0000017B0B24E7B0>.hot
 +    where <mnemocore.core.tier_manager.TierManager object at 0x0000017B0B24E7B0> = <mnemocore.core.engine.HAIMEngine object at 0x0000017B0B1FBCB0>.tier_manager
FAILED tests/test_attention_extended.py::TestXORAttentionPropertyBased::test_alpha_beta_valid_combinations - hypothesis.errors.FailedHealthCheck: It looks like this test is filtering out a lot of inputs. 0 inputs were generated successfully, while 50 inputs were filtered out. 

An input might be filtered out by calls to assume(), strategy.filter(...), or occasionally by Hypothesis internals.

Applying this much filtering makes input generation slow, since Hypothesis must discard inputs which are filtered out and try generating it again. It is also possible that applying this much filtering will distort the domain and/or distribution of the test, leaving your testing less rigorous than expected.

If you expect this many inputs to be filtered out during generation, you can disable this health check with @settings(suppress_health_check=[HealthCheck.filter_too_much]). See https://hypothesis.readthedocs.io/en/latest/reference/api.html#hypothesis.HealthCheck for details.
================= 2 failed, 2 passed, 70 deselected in 9.00s ==================
