"""
Observability Metrics (Phase 3.5.4+)
====================================
Central definition of Prometheus metrics and utility decorators.
Includes OpenTelemetry tracing support.

All metrics use the `mnemocore_*` prefix for consistency.
"""

import time
import functools
import contextvars
import warnings
from typing import Optional, Dict, Any, Callable

from prometheus_client import Counter, Histogram, Gauge, CollectorRegistry

# Create a dedicated registry for MnemoCore to avoid conflicts
REGISTRY = CollectorRegistry()

# OpenTelemetry imports (optional - gracefully degrade if not installed)
try:
    from opentelemetry import trace
    from opentelemetry.sdk.trace import TracerProvider
    from opentelemetry.sdk.trace.export import BatchSpanProcessor, ConsoleSpanExporter
    from opentelemetry.sdk.resources import Resource
    from opentelemetry.trace.propagation.tracecontext import TraceContextTextMapPropagator
    from opentelemetry.context import Context

    OTEL_AVAILABLE = True
    tracer = trace.get_tracer(__name__)
    propagator = TraceContextTextMapPropagator()
except ImportError:
    OTEL_AVAILABLE = False
    tracer = None
    propagator = None

# Context variable for trace ID propagation
_trace_id_var: contextvars.ContextVar[Optional[str]] = contextvars.ContextVar('trace_id', default=None)


# =============================================================================
# Prometheus Metrics Definitions
# All metrics use mnemocore_* prefix for consistency
# =============================================================================

# --- API Metrics ---
API_REQUEST_COUNT = Counter(
    "mnemocore_api_request_total",
    "Total API requests",
    ["method", "endpoint", "status"],
    registry=REGISTRY
)
API_REQUEST_LATENCY = Histogram(
    "mnemocore_api_request_duration_seconds",
    "API request latency",
    ["method", "endpoint"],
    buckets=[0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0],
    registry=REGISTRY
)

# --- Engine Metrics ---
MEMORY_COUNT_TOTAL = Gauge(
    "mnemocore_memory_count_total",
    "Total number of memories by tier",
    ["tier"],
    registry=REGISTRY
)

STORE_DURATION_SECONDS = Histogram(
    "mnemocore_store_duration_seconds",
    "Duration of memory store operations",
    ["tier"],
    buckets=[0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0],
    registry=REGISTRY
)

QUERY_DURATION_SECONDS = Histogram(
    "mnemocore_query_duration_seconds",
    "Duration of memory query operations",
    buckets=[0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0],
    registry=REGISTRY
)

# --- Queue Metrics ---
QUEUE_LENGTH = Gauge(
    "mnemocore_queue_length",
    "Current length of the processing queue",
    registry=REGISTRY
)

# --- Error Metrics ---
ERROR_TOTAL = Counter(
    "mnemocore_error_total",
    "Total number of errors",
    ["error_type"],
    registry=REGISTRY
)

# --- Storage Metrics (Redis/Qdrant) ---
STORAGE_OPERATION_COUNT = Counter(
    "mnemocore_storage_ops_total",
    "Storage operations",
    ["backend", "operation", "status"],
    registry=REGISTRY
)
STORAGE_LATENCY = Histogram(
    "mnemocore_storage_latency_seconds",
    "Storage operation latency",
    ["backend", "operation"],
    buckets=[0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0],
    registry=REGISTRY
)

# --- Bus Metrics ---
BUS_EVENTS_PUBLISHED = Counter(
    "mnemocore_bus_events_published_total",
    "Events published to bus",
    ["type"],
    registry=REGISTRY
)
BUS_EVENTS_CONSUMED = Counter(
    "mnemocore_bus_events_consumed_total",
    "Events consumed from bus",
    ["consumer", "type"],
    registry=REGISTRY
)

# --- Dream Loop Metrics (Subconscious background processing) ---
DREAM_LOOP_TOTAL = Counter(
    "mnemocore_dream_loop_total",
    "Total dream cycles completed",
    ["status"],  # success, error
    registry=REGISTRY
)
DREAM_LOOP_ITERATION_SECONDS = Histogram(
    "mnemocore_dream_iteration_duration_seconds",
    "Time taken for each dream loop iteration",
    [],
    buckets=[0.1, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0, 120.0],
    registry=REGISTRY
)
DREAM_LOOP_INSIGHTS_GENERATED = Counter(
    "mnemocore_dream_insights_generated_total",
    "Total insights generated by dream loop",
    ["type"],  # concept, parallel, meta
    registry=REGISTRY
)
DREAM_LOOP_ACTIVE = Gauge(
    "mnemocore_dream_loop_active",
    "Whether the dream loop is currently running (1=active, 0=stopped)",
    registry=REGISTRY
)

# --- Dream Pipeline Metrics (Task 19.3) ---
DREAM_PIPELINE_LATENCY = Histogram(
    "mnemocore_dream_pipeline_duration_seconds",
    "Duration of dream pipeline operations",
    ["operation"],  # concept_extraction, parallel_drawing, valuation, sorting
    buckets=[0.1, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0],
    registry=REGISTRY
)
DREAM_PIPELINE_ERRORS = Counter(
    "mnemocore_dream_pipeline_errors_total",
    "Total errors in dream pipeline",
    ["operation", "error_type"],
    registry=REGISTRY
)

# --- Subconscious AI Pulse Metrics (Task 19.3) ---
SUBCONSCIOUS_PULSE_LATENCY = Histogram(
    "mnemocore_subconscious_pulse_duration_seconds",
    "Duration of subconscious AI pulse operations",
    buckets=[0.1, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0],
    registry=REGISTRY
)
SUBCONSCIOUS_PULSE_SKIPS = Counter(
    "mnemocore_subconscious_pulse_skips_total",
    "Total number of skipped subconscious pulses",
    ["reason"],  # idle, high_cpu, disabled, backpressure
    registry=REGISTRY
)

# --- Webhook Delivery Metrics (Task 19.3) ---
WEBHOOK_DELIVERY_TOTAL = Counter(
    "mnemocore_webhook_delivery_total",
    "Total webhook delivery attempts",
    ["status"],  # success, failure, retry
    registry=REGISTRY
)
WEBHOOK_DELIVERY_LATENCY = Histogram(
    "mnemocore_webhook_delivery_duration_seconds",
    "Duration of webhook delivery operations",
    buckets=[0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0],
    registry=REGISTRY
)

# --- Backup/Restore Operation Metrics (Task 19.3) ---
BACKUP_OPERATION_LATENCY = Histogram(
    "mnemocore_backup_operation_duration_seconds",
    "Duration of backup/restore operations",
    ["operation"],  # backup, restore, snapshot
    buckets=[0.1, 0.5, 1.0, 2.5, 5.0, 10.0, 30.0, 60.0, 120.0, 300.0],
    registry=REGISTRY
)
BACKUP_OPERATION_TOTAL = Counter(
    "mnemocore_backup_operation_total",
    "Total backup/restore operations",
    ["operation", "status"],  # operation: backup/restore/snapshot, status: success/failure
    registry=REGISTRY
)

# --- Working Memory Metrics (Task 19.3) ---
WORKING_MEMORY_SIZE = Gauge(
    "mnemocore_working_memory_size",
    "Current size of working memory",
    ["component"],  # engine, consolidator, dream_loop, etc.
    registry=REGISTRY
)
WORKING_MEMORY_CAPACITY = Gauge(
    "mnemocore_working_memory_capacity",
    "Maximum capacity of working memory",
    ["component"],
    registry=REGISTRY
)


# =============================================================================
# Backward Compatibility Aliases (deprecated, will be removed in v6.0)
# =============================================================================

# Deprecated: Use MEMORY_COUNT_TOTAL instead
ENGINE_MEMORY_COUNT = MEMORY_COUNT_TOTAL

# Deprecated: Use STORE_DURATION_SECONDS instead
ENGINE_STORE_LATENCY = STORE_DURATION_SECONDS

# Deprecated: Use QUERY_DURATION_SECONDS instead
ENGINE_QUERY_LATENCY = QUERY_DURATION_SECONDS


# =============================================================================
# OpenTelemetry Configuration
# =============================================================================

def init_opentelemetry(service_name: str = "mnemocore", exporter: str = "console") -> Optional["TracerProvider"]:
    """
    Initialize OpenTelemetry tracing.

    Args:
        service_name: Name of the service for tracing.
        exporter: Exporter type ('console', 'otlp', or 'none').

    Returns:
        TracerProvider if OTEL is available, None otherwise.
    """
    if not OTEL_AVAILABLE:
        return None

    resource = Resource.create({"service.name": service_name})
    provider = TracerProvider(resource=resource)

    if exporter == "console":
        processor = BatchSpanProcessor(ConsoleSpanExporter())
        provider.add_span_processor(processor)
    elif exporter == "otlp":
        try:
            from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
            processor = BatchSpanProcessor(OTLPSpanExporter())
            provider.add_span_processor(processor)
        except ImportError:
            # Fallback to console if OTLP exporter not available
            processor = BatchSpanProcessor(ConsoleSpanExporter())
            provider.add_span_processor(processor)

    trace.set_tracer_provider(provider)
    return provider


def get_trace_id() -> Optional[str]:
    """Get the current trace ID from context."""
    return _trace_id_var.get()


def set_trace_id(trace_id: str) -> None:
    """Set the trace ID in context."""
    _trace_id_var.set(trace_id)


def extract_trace_context(headers: Dict[str, str]) -> Optional[str]:
    """
    Extract trace context from HTTP headers.

    Args:
        headers: Dictionary of HTTP headers.

    Returns:
        The trace ID if found, None otherwise.
    """
    if not OTEL_AVAILABLE or propagator is None:
        return None

    ctx = propagator.extract(headers)
    span_ctx = trace.get_current_span(ctx).get_span_context()

    if span_ctx.is_valid:
        trace_id = format(span_ctx.trace_id, '032x')
        set_trace_id(trace_id)
        return trace_id

    return None


def inject_trace_context() -> Dict[str, str]:
    """
    Inject trace context into HTTP headers.

    Returns:
        Dictionary with trace headers.
    """
    if not OTEL_AVAILABLE or propagator is None:
        return {}

    headers: Dict[str, str] = {}
    propagator.inject(headers)
    return headers


# =============================================================================
# Decorators
# =============================================================================

def timer(metric: Histogram, labels: Optional[Dict[str, str]] = None):
    """
    Timer decorator for async functions with OpenTelemetry span support.
    This is the primary timer decorator - use this for all new code.

    Usage:
        @timer(STORE_DURATION_SECONDS, labels={"tier": "hot"})
        async def store(...):
            ...
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()

            # Create OTEL span if available
            span = None
            if OTEL_AVAILABLE and tracer is not None:
                span = tracer.start_span(func.__name__)

            try:
                result = await func(*args, **kwargs)
                return result
            except Exception as e:
                # Increment error counter
                error_type = type(e).__name__
                ERROR_TOTAL.labels(error_type=error_type).inc()

                if span:
                    span.record_exception(e)
                raise
            finally:
                duration = time.time() - start_time

                # Record Prometheus metric
                if labels:
                    metric.labels(**labels).observe(duration)
                else:
                    metric.observe(duration)

                # End OTEL span
                if span:
                    span.set_attribute("duration_seconds", duration)
                    trace_id = get_trace_id()
                    if trace_id:
                        span.set_attribute("trace_id", trace_id)
                    span.end()

        return wrapper
    return decorator


def track_latency(metric: Histogram, labels: dict = None):
    """
    Decorator to track synchronous function execution time.

    DEPRECATED: Use `timer` decorator instead.
    This will be removed in v6.0.
    """
    warnings.warn(
        "track_latency is deprecated, use timer decorator instead",
        DeprecationWarning,
        stacklevel=2
    )

    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = func(*args, **kwargs)
                return result
            finally:
                duration = time.time() - start_time
                if labels:
                    metric.labels(**labels).observe(duration)
                else:
                    metric.observe(duration)
        return wrapper
    return decorator


def track_async_latency(metric: Histogram, labels: dict = None):
    """
    Decorator to track async function execution time.

    DEPRECATED: Use `timer` decorator instead.
    This will be removed in v6.0.
    """
    warnings.warn(
        "track_async_latency is deprecated, use timer decorator instead",
        DeprecationWarning,
        stacklevel=2
    )

    def decorator(func):
        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = await func(*args, **kwargs)
                return result
            finally:
                duration = time.time() - start_time
                if labels:
                    metric.labels(**labels).observe(duration)
                else:
                    metric.observe(duration)
        return wrapper
    return decorator


def traced(name: Optional[str] = None):
    """
    Decorator to create an OpenTelemetry span for a function.

    Usage:
        @traced("my_operation")
        async def my_function(...):
            ...
    """
    def decorator(func: Callable) -> Callable:
        span_name = name or func.__name__

        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            if not OTEL_AVAILABLE or tracer is None:
                return await func(*args, **kwargs)

            with tracer.start_as_current_span(span_name) as span:
                trace_id = get_trace_id()
                if trace_id:
                    span.set_attribute("trace_id", trace_id)

                try:
                    result = await func(*args, **kwargs)
                    return result
                except Exception as e:
                    span.record_exception(e)
                    raise

        return wrapper
    return decorator


# =============================================================================
# Helper Functions
# =============================================================================

def update_memory_count(tier: str, count: int) -> None:
    """Update the memory count gauge for a specific tier."""
    MEMORY_COUNT_TOTAL.labels(tier=tier).set(count)


def update_queue_length(length: int) -> None:
    """Update the queue length gauge."""
    QUEUE_LENGTH.set(length)


def record_error(error_type: str) -> None:
    """Record an error in the error counter."""
    ERROR_TOTAL.labels(error_type=error_type).inc()


def update_working_memory_size(component: str, size: int) -> None:
    """Update the working memory size gauge for a component."""
    WORKING_MEMORY_SIZE.labels(component=component).set(size)


def update_working_memory_capacity(component: str, capacity: int) -> None:
    """Update the working memory capacity gauge for a component."""
    WORKING_MEMORY_CAPACITY.labels(component=component).set(capacity)


def record_dream_pipeline_latency(operation: str, duration: float) -> None:
    """Record dream pipeline operation latency."""
    DREAM_PIPELINE_LATENCY.labels(operation=operation).observe(duration)


def record_dream_pipeline_error(operation: str, error_type: str) -> None:
    """Record dream pipeline operation error."""
    DREAM_PIPELINE_ERRORS.labels(operation=operation, error_type=error_type).inc()


def record_subconscious_pulse_latency(duration: float) -> None:
    """Record subconscious AI pulse latency."""
    SUBCONSCIOUS_PULSE_LATENCY.observe(duration)


def record_subconscious_pulse_skip(reason: str) -> None:
    """Record a skipped subconscious pulse."""
    SUBCONSCIOUS_PULSE_SKIPS.labels(reason=reason).inc()


def record_webhook_delivery(status: str, duration: float) -> None:
    """Record webhook delivery result."""
    WEBHOOK_DELIVERY_TOTAL.labels(status=status).inc()
    WEBHOOK_DELIVERY_LATENCY.observe(duration)


def record_backup_operation(operation: str, status: str, duration: float) -> None:
    """Record backup/restore operation result."""
    BACKUP_OPERATION_TOTAL.labels(operation=operation, status=status).inc()
    BACKUP_OPERATION_LATENCY.labels(operation=operation).observe(duration)
